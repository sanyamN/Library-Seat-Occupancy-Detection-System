# -*- coding: utf-8 -*-
"""Capstone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HfA230wtvIYKwNJZSg0V4y_VqRIoGf0d
"""




from ultralytics import YOLO
from PIL import Image
import matplotlib.pyplot as plt
import time



# Load the trained YOLOv8 model
model = YOLO("best.pt")

# Function to test the model on a single image and display counts
def predict_image(image_path):
    # Load the image
    img = Image.open(image_path)

    # Perform the prediction
    results = model.predict(img)

    # Initialize counters
    occupied_count = 0
    unoccupied_count = 0

    # Plot the image with the prediction boxes
    plt.figure(figsize=(10, 10))
    plt.imshow(img)
    ax = plt.gca()

    # Loop through the detections and add them to the plot
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()  # Move the tensor to CPU and convert to NumPy
            conf = box.conf[0].cpu().numpy()
            label = model.names[int(box.cls[0].cpu().numpy())]

            if label == 'Occupied':
                occupied_count += 1
            elif label == 'Unoccupied':
                unoccupied_count += 1

            # Draw the box
            rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, color='red', linewidth=2)
            ax.add_patch(rect)

            # Draw the label
            plt.text(x1, y1, f'{label} {conf:.2f}', color='red', fontsize=12, verticalalignment='top', bbox=dict(facecolor='white', alpha=0.5))

    # Display the counts on the image
    plt.text(10, 30, f'Occupied: {occupied_count}', color='red', fontsize=15, bbox=dict(facecolor='white', alpha=0.5))
    plt.text(10, 60, f'Unoccupied: {unoccupied_count}', color='red', fontsize=15, bbox=dict(facecolor='white', alpha=0.5))

    plt.axis('off')
    plt.show()




import cv2
import numpy as np


# Function to process and display the frame with predictions
def process_frame(frame):
    # Convert the frame to RGB
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Perform the prediction
    results = model.predict(rgb_frame)

    # Loop through the detections and add them to the frame
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()  # Move the tensor to CPU and convert to NumPy
            conf = box.conf[0].cpu().numpy()
            label = model.names[int(box.cls[0].cpu().numpy())]

            # Draw the box
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)

            # Draw the label
            cv2.putText(frame, f'{label} {conf:.2f}', (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    return frame

# Capture video from the laptop's camera
#cap = cv2.VideoCapture("http://192.168.74.153:8080/video")
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("Error: Could not open video stream from camera.")
    exit()

while True:
    # Capture frame-by-frame
    ret, frame = cap.read()

    if not ret:
        print("Error: Failed to capture image")
        break

    # Process the frame
    processed_frame = process_frame(frame)

    
    # Display the resulting frame
    cv2.imshow('Real-time Object Detection', processed_frame)
    

    # Break the loop on 'q' key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# When everything is done, release the capture and close windows
cap.release()
cv2.destroyAllWindows()

'''
from flask import Flask, render_template_string

app = Flask(__name__)

# Define the HTML template as a string
html_template = """
<!DOCTYPE html>
<html>
<head>
    <title>Flask Demo</title>
</head>
<body>
    <h1>Welcome to Flask Demo!</h1>
    <p>This is a basic Flask app with HTML rendered in the browser.</p>
    <h2>Seats Status:</h2>
    <ul>
        <li>Seat 1: {{ seat_1 }}</li>
        <li>Seat 2: {{ seat_2 }}</li>
        <li>Seat 3: {{ seat_3 }}</li>
    </ul>
</body>
</html>
"""

# Route to render the HTML
@app.route('/')
def home():
    # Pass data to the HTML template
    return render_template_string(html_template, seat_1="Occupied", seat_2="Not Occupied", seat_3="Occupied")

# Start the Flask application
if __name__ == '__main__':
    app.run(debug=True)'''
    
    
        
from flask import Flask, render_template, Response
import cv2

app = Flask(__name__)

# Initialize the webcam capture
camera = cv2.VideoCapture(1)  # Use 0 for the default webcam

def generate_frames():
    while True:
        # Read the frame from the webcam
        success, frame = camera.read()
        if not success:
            break
        else:
            # Encode the frame in JPEG format
            ret, buffer = cv2.imencode('.jpg', frame)
            frame = buffer.tobytes()

            # Yield the frame in byte format to the browser
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

@app.route('/')
def index():
    # Render the HTML page
    return render_template('index.html')

@app.route('/video_feed')
def video_feed():
    # Return the response generated from the camera frames
    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == '__main__':
    app.run(debug=True)

